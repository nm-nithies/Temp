The ONNX operation seems to have an attribute `stash_type` that can be used to specify the data type used for the calculations, see Operators.md#GroupNormalization
Maybe this can be used to improve the accuracy? InstanceNormalization does not seem to have this, so maybe it is always using a more accurate data type?

What output of the model do you exactly compare? Do you compare latent_sample?
This output depend on the output of RandomNormalLike_496 which generates random numbers. If these are real random numbers (instead of pseudo random based on a seed) it is expected that the output latent_sample output will be different. You will have to compare tensors before this operation, eg moments
