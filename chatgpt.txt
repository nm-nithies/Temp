In most cases, broadcasting works right-to-left, so we pad 1s from the front to match the Conv weight shape.
For example, (64, 64, 3, 3) with a Mul constant (3, 3) becomes (1, 1, 3, 3).

But in some regression models like DAN, left-to-right broadcasting seems to apply.
Example: (64, 64, 3, 3) with Mul shape (64) â†’ becomes (64, 1, 1, 1).

This is tricky when dimensions like input/output channels or batch are equal (e.g., both 64), making it hard to tell what the constant is meant to scale.
Right now, left-to-right works for our regression models, but it's ambiguous in general.
Still figuring out how best to reliably detect which dim is meant to be broadcasted.
