For the RMSNormalization pattern 2 in the QwenVL decoder model, I identified the reason for the observed max_diff.

Initially, the pattern uses a ReduceL2 op which internally applies np.sum(), whereas RMSNormalization uses np.mean() for its calculation. This mismatch in reduction functions is the root cause of the numerical difference.

To address this, we could consider writing a custom RMSNormalization op that replaces np.mean() with np.sum() during computation. I tested the pattern using np.sum() instead of np.mean() and confirmed that it can be successfully legalized.

For Pattern 1 (used in LLaMA2 and LLaMA3), I tested the RMS normalization pattern and confirmed that it gets successfully legalized.

In the current LLaMA RMS pattern, there are Cast operations at the beginning and end of the sequence (from float16 to float32, and back). I believe this is the primary reason for the observed max_diff.
Yvonne, could you confirm if this is correct?

Also, would it be appropriate to use the --legalize-error option to handle this difference?
