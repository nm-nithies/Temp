import torch
import torch.nn as nn

class ExactInstanceNormPattern(nn.Module):
    def __init__(self):
        super().__init__()
        # InstanceNorm1d with fixed scale=1 and bias=0
        self.instancenorm = nn.InstanceNorm1d(32, affine=False)

        # Scale and bias after reshape
        self.mul_weight = nn.Parameter(torch.randn(128, 1, 1))  # Learnable scale
        self.add_bias = nn.Parameter(torch.randn(128, 1, 1))    # Learnable bias

    def forward(self, x):
        # x: [1, 128, 512, 512]
        N, C, H, W = x.shape

        # Step 1: reshape to [1, 32, 128*512*512/32] = [1, 32, 1048576]
        x = x.view(N, 32, -1)

        # Step 2: apply instance normalization with scale=1, bias=0
        x = self.instancenorm(x)

        # Step 3: reshape back to [1, 128, 512, 512]
        x = x.view(N, C, H, W)

        # Step 4: Mul (scale per channel)
        x = x * self.mul_weight

        # Step 5: Add (bias per channel)
        x = x + self.add_bias

        return x

# Instantiate model
model = ExactInstanceNormPattern()
model.eval()

# Input tensor
x = torch.randn(1, 128, 512, 512)

# Export to ONNX
torch.onnx.export(
    model,
    x,
    "instancenorm_fusion_pattern.onnx",
    input_names=["input"],
    output_names=["output"],
    dynamic_axes={"input": {0: "batch"}, "output": {0: "batch"}},
    opset_version=11
)

print("Exported to instancenorm_fusion_pattern.onnx")
