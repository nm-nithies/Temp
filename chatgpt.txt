[INFO] Update model Opset version from 13 to 23.
/github/workspace/onnx/version_converter/convert.h:86: assertInVersionRange: Assertion `version >= version_range.first && version <= version_range.second` failed: Warning: invalid version (must be between 1 and 21)
onnxruntime_extensions import failed due to error: [ONNXRuntimeError] : 2 : INVALID_ARGUMENT : Failed to load model with error: /hdd2/lucia/build_onnxruntime_1.19/onnxruntime/onnxruntime/core/graph/model_load_utils.h:46 void onnxruntime::model_load_utils::ValidateOpsetForDomain(const std::unordered_map<std::__cxx11::basic_string<char>, int>&, const onnxruntime::logging::Logger&, bool, const string&, int) ONNX Runtime only *guarantees* support for models stamped with official released onnx opset versions. Opset 23 is under development and support for this is limited. The operator schemas and or other functionality may change before next ONNX release and in this case ONNX Runtime will not guarantee backward compatibility. Current official support for domain ai.onnx is till opset 21.

[WARNING] ONNX simplify not successfully performed due to error: [ONNXRuntimeError] : 2 : INVALID_ARGUMENT : Failed to load model with error: /hdd2/lucia/build_onnxruntime_1.19/onnxruntime/onnxruntime/core/graph/model_load_utils.h:46 void onnxruntime::model_load_utils::ValidateOpsetForDomain(const std::unordered_map<std::__cxx11::basic_string<char>, int>&, const onnxruntime::logging::Logger&, bool, const string&, int) ONNX Runtime only *guarantees* support for models stamped with official released onnx opset versions. Opset 23 is under development and support for this is limited. The operator schemas and or other functionality may change before next ONNX release and in this case ONNX Runtime will not guarantee backward compatibility. Current official support for domain ai.onnx is till opset 21.

[INFO] Available RAM in system: 473.063084032 GB
[INFO] Set cpu_cores to be 16 for Onnxruntime inference.
Traceback (most recent call last):
  File "/remote/us01sgnfs00562/NNSDK/nithies/nnsdk/nnac/frontend/nnac.py", line 16, in <module>
    nnac_integrate_cli()
  File "/remote/us01sgnfs00562/NNSDK/nithies/nnsdk/nnac/frontend/nnac/nnac_integrate_cli.py", line 147, in nnac_integrate_cli
    legalized_model = legalize(model=converted_model,
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/remote/us01sgnfs00562/NNSDK/nithies/nnsdk/nnac/frontend/nnac/legalizer/legalize.py", line 63, in legalize
    opt_model, _, _, _ = optimization(
                         ^^^^^^^^^^^^^
  File "/remote/us01sgnfs00562/NNSDK/nithies/nnsdk/nnac/frontend/nnac/legalizer/optimization_controller.py", line 541, in optimization
    optimized_model, _, passes_counter, _ = optimize_onnx_ops(
                                            ^^^^^^^^^^^^^^^^^^
  File "/remote/us01sgnfs00562/NNSDK/nithies/nnsdk/nnac/frontend/nnac/legalizer/custom_optimize_onnx_ops.py", line 1010, in optimize_onnx_ops
    optimizer.SetInputModel(onnx_model_path_or_def, data_format, input_npy, compare_dict)
  File "/remote/us01sgnfs00562/NNSDK/nithies/nnsdk/nnac/frontend/nnac/legalizer/custom_optimize_onnx_ops.py", line 214, in SetInputModel
    self.ShapeDict, self.TypeDict = check_exist_and_only_collect_rest_value_info_by_run(
                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/remote/us01sgnfs00562/NNSDK/nithies/nnsdk/nnac/frontend/nnac/core/utils.py", line 647, in check_exist_and_only_collect_rest_value_info_by_run
    gen_shape_dict, gen_type_dict = _gen_shape_dict_dry_run(model_def, True, input_npy,
                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/remote/us01sgnfs00562/NNSDK/nithies/nnsdk/nnac/frontend/nnac/core/utils.py", line 384, in _gen_shape_dict_dry_run
    sess = onnxruntime_session_setup(model, optimizer_level=rt.GraphOptimizationLevel.ORT_DISABLE_ALL)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/remote/us01sgnfs00562/NNSDK/nithies/nnsdk/nnac/frontend/nnac/core/onnx_inference.py", line 237, in onnxruntime_session_setup
    sess = rt.InferenceSession(
           ^^^^^^^^^^^^^^^^^^^^
  File "/slowfs/us01dwt2p219/ARCJenkinsTools/ToolsCommon/SynopsysCaffe/1.6-eng1-nocuda-MX/Linux/lib/python3.11/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 419, in __init__
    self._create_inference_session(providers, provider_options, disabled_optimizers)
  File "/slowfs/us01dwt2p219/ARCJenkinsTools/ToolsCommon/SynopsysCaffe/1.6-eng1-nocuda-MX/Linux/lib/python3.11/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py", line 482, in _create_inference_session
    sess = C.InferenceSession(session_options, self._model_bytes, False, self._read_config_from_model)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
onnxruntime.capi.onnxruntime_pybind11_state.InvalidArgument: [ONNXRuntimeError] : 2 : INVALID_ARGUMENT : Failed to load model with error: /hdd2/lucia/build_onnxruntime_1.19/onnxruntime/onnxruntime/core/graph/model_load_utils.h:46 void onnxruntime::model_load_utils::ValidateOpsetForDomain(const std::unordered_map<std::__cxx11::basic_string<char>, int>&, const onnxruntime::logging::Logger&, bool, const string&, int) ONNX Runtime only *guarantees* support for models stamped with official released onnx opset versions. Opset 23 is under development and support for this is limited. The operator schemas and or other functionality may change before next ONNX release and in this case ONNX Runtime will not guarantee backward compatibility. Current official support for domain ai.onnx is till opset 21.
