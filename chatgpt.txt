import torch
import torch.nn as nn
import torch.onnx

class TwoBranchConcatModel(nn.Module):
    def __init__(self):
        super().__init__()
        self.weight1 = nn.Parameter(torch.randn(256, 64) * 0.1 + 0.5)
        self.bias1 = nn.Parameter(torch.randn(64) * 0.1 + 0.5)
        self.weight2 = nn.Parameter(torch.randn(256, 128) * 0.1 + 0.5)
        self.bias2 = nn.Parameter(torch.randn(128) * 0.1 + 0.5)

    def forward(self, x1, x2):
        out1 = torch.matmul(x1, self.weight1) + self.bias1
        out2 = torch.matmul(x2, self.weight2) + self.bias2
        reshaped1 = out1.reshape(x1.shape[0], x1.shape[1], -1)
        reshaped2 = out2.reshape(x2.shape[0], x2.shape[1], -1)
        concatenated = torch.cat([reshaped1, reshaped2], dim=-1)
        return concatenated

# Create model and inputs
model = TwoBranchConcatModel().eval()
x1 = torch.randn(1, 2500, 256)
x2 = torch.randn(1, 2500, 256)

# Export to ONNX
torch.onnx.export(
    model,
    (x1, x2),
    "explicit_concat.onnx",
    input_names=["input1", "input2"],
    output_names=["output"],
    opset_version=11,
    do_constant_folding=False,  # Ensures operations like concat are preserved
    dynamic_axes={
        "input1": {0: "batch", 1: "seq"},
        "input2": {0: "batch", 1: "seq"},
        "output": {0: "batch", 1: "seq"}
    }
)
