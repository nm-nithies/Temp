import torch
import torch.nn as nn
import torch.onnx
import onnx
from onnx import shape_inference

class CustomGraph(nn.Module):
    def __init__(self):
        super(CustomGraph, self).__init__()
        self.constant = nn.Parameter(torch.tensor([1.0, 2.0, 3.0]), requires_grad=False)

    def forward(self, x):
        # x is input tensor of shape [B, 3, 2] (example shape)
        const_add = self.constant + 1.0                         # [3]
        unsqueezed = const_add.unsqueeze(0)                     # [1, 3]
        concat = torch.cat([unsqueezed, unsqueezed], dim=0)     # [2, 3]
        reshaped = concat.reshape(1, 6)                          # [1, 6]

        transposed = x.transpose(1, 2)                           # e.g., [B, 2, 3]
        transposed_flat = transposed.reshape(1, 6)               # match shape with reshaped

        added = reshaped + transposed_flat                      # [1, 6]
        multiplied = added * 2.0                                # [1, 6]
        return multiplied

# Create dummy input
dummy_input = torch.randn(1, 3, 2)  # Adjust as needed

# Instantiate model
model = CustomGraph()

# Export to ONNX
onnx_path = "custom_graph.onnx"
torch.onnx.export(model, dummy_input, onnx_path,
                  input_names=['input'], output_names=['output'],
                  opset_version=13, dynamic_axes={'input': {0: 'batch_size'}})

# Load and run shape inference
onnx_model = onnx.load(onnx_path)
inferred_model = shape_inference.infer_shapes(onnx_model)

# Save inferred model (optional)
inferred_path = "custom_graph_inferred.onnx"
onnx.save(inferred_model, inferred_path)

# Print inferred output shape
for output in inferred_model.graph.output:
    print(f"Output name: {output.name}")
    print(f"Shape: {[dim.dim_value for dim in output.type.tensor_type.shape.dim]}")
