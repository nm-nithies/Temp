Fixed the legalization issue in the FuseMulIntoConv pass by broadcasting Mul constants to match Conv weights for proper fusion. Also added a check to skip fusion when the Mul constants contain negative values, as they cannot be legally fused into Conv.
Pushed the code and Build passed.

Resolved MR comments
Fixed issues in regression failed models.  Faced max_diff values to Dan Model in regression. Cleaned and push the code.
 
For broadcasting mul_constant to map conv weights:
In most cases, broadcasting works right-to-left, so we pad 1s from the front to match the Conv weight shape.
For example, (64, 64, 3, 3) with a Mul constant (3, 3) becomes (1, 1, 3, 3).
But in some regression models like DAN and Efficientnetb0, left-to-right broadcasting seems to apply.
Example: (64, 64, 3, 3) with Mul shape (64) becomes (64, 1, 1, 1).
Example: (1280,320,1,1) with Mul shape (1280) becomed (1280,1,1,1,)
This is tricky when dimensions like input/output channels or batch are equal (e.g., both 64), making it hard to tell what the constant is meant to scale.
Right now, left-to-right works for our regression models, but it's ambiguous in general.
Still figuring out how best to reliably detect which dim is meant to be broadcasted.
 
For now the code changes passes the build.
I think previously, this pass has been skipped for Dan model due to this issues. Now this pass had been applied to dan model without  max_diff errors


Replaced all scatternd ops with concat and slice ops.
Later found this change does not replace one of the scatternd in the model_dn_subgraph.
Yet to fix ,clean and push the codes.
